"""
Utilities
"""


from random import shuffle, randint, sample
import itertools

import pref_voting
from pref_voting.profiles import Profile

from pref_voting.scoring_methods import plurality, borda, anti_plurality
from pref_voting.c1_methods import condorcet, copeland, copeland, llull, uc_gill, top_cycle, banks, slater
from pref_voting.iterative_methods import instant_runoff_tb, plurality_with_runoff_put, coombs, baldwin, weak_nanson
from pref_voting.margin_based_methods import minimax, split_cycle, river, stable_voting, ranked_pairs
from pref_voting.combined_methods import blacks
from pref_voting.other_methods import kemeny_young

from scipy.stats import kendalltau

import axioms as ax 



# Lists

def flatten_list(input_list):
    """Flattens a list"""
    return [item for sublist in input_list for item in sublist]

def zero_list(n):
    return [0 for _ in range(n)]

def onehot(alt, max_num_alternatives):
    vec = zero_list(max_num_alternatives)
    vec[alt] = 1
    return vec


# Winning sets

def winner_to_vec (winner_list, num_alternatives):
    """
    Recasts winning set into characteristic function (binary list) 

    Voting rules output a list of winners among the alternatives (cast as list). 
    Sometimes we turn this into a binary list where the n-th entry is 1 iff the 
    n-th alternative is a winner.

    Example: winner_to_vec([0,1,3], 5) = [1, 1, 0, 1, 0]
    """
    vec = []
    for i in range(num_alternatives):
        vec.append(int(i in winner_list))
    return vec


# Rankings

def ranking_to_onehot(ranking, max_num_voters, max_num_alternatives):
    return [onehot(alt, max_num_alternatives) for alt in ranking]



# Profiles

def recast_profile_wo_mult(prof):
    """
    Recasts a profile into one with rcounts all 1
    
    The profiles generated by *generate_profile* allow rcounts (i.e., how 
    often a given ranking appears) different from just 1's. But for us the 
    order of the submitted rankings matter, not just their number. 
    So we recast this into a profile with rcounts all 1.

    Example: The profile prof = Profile([[0, 1], [1, 0]], rcounts = [2, 1])
    is recast to [(0, 1), (0, 1), (1, 0)].
    """
    rankings_list = prof.rankings
    shuffle(rankings_list)
    return Profile(rankings_list)



def padded_profile_list(prof, max_num_voters, max_num_alternatives):
    """
    Pads a profile with -1's to the desired number of voters and alternatives
    
    Input: A profile `prof` (in the sense of the `pref_voting` package), an 
    integer `max_num_voters` and an integer `max_num_alternatives`.

    We pad with -1's because the naming convention for alternatives in the 
    `pref_voting` package is 0,1,2,..., so 0 is already taken.

    Output: A profile in the form of a list of lists padded by -1's to have 
    rankings of length `max_number_alternatives` and `max_num_voters` many 
    rankings.

    Example: The profile prof = Profile([[0, 1], [1, 0]]) is padded to 
    padded_profile_list(prof,3,3) = [[0, 1, -1], [1, 0, -1], [-1, -1, -1]]
    """
    
    assert prof.num_voters <= max_num_voters, f'The profile has more voters (namely {prof.num_voters}) than padding space (which is {max_num_voters})'
    assert prof.num_cands <= max_num_alternatives, f'The profile has more alternatives (namely {prof.num_cands}) than padding space (which is {max_num_alternatives})'

    padded_profile = []
    for ranking in prof.rankings:
        padded_profile.append(list(ranking) + [-1 for i in range(prof.num_cands,max_num_alternatives)])
    for j in range(prof.num_voters,max_num_voters):
        padded_profile.append([-1 for i in range(0,max_num_alternatives)])
    return padded_profile


def profile_to_onehot(profile, max_num_voters, max_num_alternatives):
    """
    Return list of rankings where each alternative is replaced by its one-hot 
    vector, and zero vectors are added to pad up to length `max_num_voters`
    """
    one_hot_profile = []
    for ranking in profile.rankings:
        one_hot_ranking = [onehot(alt, max_num_alternatives) for alt in ranking]
        # add the remaining alternatives
        one_hot_ranking += [zero_list(max_num_alternatives) for _ in range(profile.num_cands,max_num_alternatives)]
        one_hot_profile.append(one_hot_ranking)
    for j in range(profile.num_voters,max_num_voters):
        one_hot_profile.append([zero_list(max_num_alternatives) for _ in range(max_num_alternatives)])
    return one_hot_profile


def flatten_onehot_profile(prof_list):
    prof_flattened = []
    for ranking in prof_list:
        prof_flattened += flatten_list(ranking)
    return prof_flattened




def ranking_to_pairs(ranking):
    """
    Takes a ranking and return the set of pairs of elements in the same ranking

    For example, the ranking [a,b,c] is mapped to the set {(a,b), (a,c), (b,c)} 
    """
    return set(itertools.combinations(ranking, 2))

def kendall_tau_distance(ranking1, ranking2):
    """
    Takes two rankings and outputs their Kendall Tau distance
    
    Assumes ranking1 and ranking2 to be over the same set of alternatives
    """
    pairs1 = ranking_to_pairs(ranking1)
    pairs2 = ranking_to_pairs(ranking2)
    difference = len(pairs1 - pairs2)
    # normalization is not needed since same underlying set of alternatives
    return difference


def kendall_tau_order(profile, version):
    """
    Takes a profile and outputs it Kendall Tau ordered.

    For a profile [r_0, ..., r_{n-1}], the ordering can be done in two 
    versions: 
    
    1) 'global': compute, for k = 1, ..., n-1, the Kendall Tau distance d_k 
    between r_0 and r_k. Rewrite the profile starting with r_0 and then the 
    other rankings with ascending d_k (so similar profiles come first, then 
    less similar ones). 

    2) 'local': The ordered profile [r'_0, ..., r'_{n-1}] is computed 
    recursively as follows. Set r'_0 = r_0. Given r'_k, we determine r'_{k+1} 
    as follows. Go through the rankings that haven't been picked yet (i.e., 
    {r_0, ..., r_{n-1}} \ {r'_0, ..., r'_k}) and compute their Kendall Tau 
    distance to r'_k. Then r'{k+1} is the ranking which is closest to r'_k, 
    i.e., with smallest Kendall Tau distance.
    """
    rankings = profile.rankings
    if version == 'global':
        # compute the kendall tau distance d_k between r_0 and r_k
        # stipulating the distance d_0 between r_0 and r_0 to be -1, so
        # it is closer to itself than any other
        distances_from_first = {0:-1}
        for k in range(1,len(rankings)):
            distance = kendall_tau_distance(rankings[0], rankings[k])
            distances_from_first[k]=distance
        # Sort the rankings by ascending distance
        distances_sorted = dict(sorted(
            distances_from_first.items(),
            key=lambda item: item[1],
            reverse=False
        ))
        # Reorder the profiles accordingly
        ordered_rankings = [rankings[k] for k in distances_sorted.keys()]

    if version == 'local':
        # initialize the list of ordered ranking indices with the first ranking
        ordered_rankings = [0]
        # for later use, the list of all ranking indices
        all_rankings = {idx for idx in range(len(rankings))}
        # a flag that will be set to True if search was stopped early
        stopped_early = False
        for k in range(1, len(rankings)):
            last_ranking = rankings[ordered_rankings[-1]]
            remaining_rankings = all_rankings - set(ordered_rankings)
            # compute distances of remaining rankings to last ranking
            distances_remaining = {}
            for j in remaining_rankings:
                distance = kendall_tau_distance(last_ranking, rankings[j])
                distances_remaining[j] = distance
                # stop search early if maximal similarity reached
                if distance == 0:
                    stopped_early = True
                    break
            if stopped_early:
                argmin_j=j
            else: 
                argmin_j=min(distances_remaining, key=distances_remaining.get)
            ordered_rankings.append(argmin_j)
        ordered_rankings = [rankings[k] for k in ordered_rankings]

    return Profile(ordered_rankings)



# Voting data to json

def voting_data_to_json(X,y):
    """
    Casts voting data into json-serializable dictionary 
    
    X is a list of profiles, y is a list of corresponding winning sets.
    """
    train_data = {
            f"{row}": {
                "Prof": {
                    f"{voter}": [int(a) for a in ranking]
                    for voter, ranking in enumerate(X[row].rankings)
                },
                "Win": y[row],
            }
            for row in range(len(X))
        }
    return train_data


def json_to_voting_data(train_data):
    """
    Undoes `voting_data_to_json`
    """
    X = []
    y = []
    for row in train_data.keys():
        profile = Profile(list(train_data[row]['Prof'].values()))
        winning_set = train_data[row]['Win']
        X.append(profile)
        y.append(winning_set)
    return X, y



# The random rule

def rand_rule (prof):
    """
    A voting rule that a outputs a random winning set, no matter the input
    """
    list_of_alternatives = prof.candidates
    num_winners = randint(1,len(list_of_alternatives))
    list_winners = sample(list_of_alternatives, num_winners)
    return list_winners


# Dictionaries of voting rules

dict_rules = {
    'Plurality':plurality,
    'Borda':borda,
    'Copeland':copeland,
    'RandomRule':rand_rule
}


# The names are as given in the `pref_voting`` package
dict_rules_all_fast ={
    'Plurality' : plurality,
    'Borda' : borda, 
    'Anti-Plurality' : anti_plurality, 
    'Copeland' : copeland, 
    'Llull' : llull, 
    'Uncovered Set' : uc_gill, 
    'Top Cycle' : top_cycle, 
    'Banks' : banks, 
    'Stable Voting' : stable_voting,
    'Blacks' : blacks, 
    'Instant Runoff TB' : instant_runoff_tb, 
    'PluralityWRunoff PUT' : plurality_with_runoff_put, 
    'Coombs' : coombs, 
    'Baldwin' : baldwin, 
    'Weak Nanson' : weak_nanson,
    'Kemeny-Young' : kemeny_young
}

# The names are as given in the `pref_voting`` package
dict_rules_all ={
    'Plurality' : plurality,
    'Borda' : borda, 
    'Anti-Plurality' : anti_plurality, 
    'Copeland' : copeland, 
    'Llull' : llull, 
    'Uncovered Set' : uc_gill, 
    'Top Cycle' : top_cycle, 
    'Banks' : banks, 
    'Slater' : slater, 
    'Minimax' : minimax,
    'Split Cycle' : split_cycle,
    'River' : river, 
    'Stable Voting' : stable_voting,
    'Ranked Pairs' : ranked_pairs,
    'Blacks' : blacks, 
    'Instant Runoff TB' : instant_runoff_tb, 
    'PluralityWRunoff PUT' : plurality_with_runoff_put, 
    'Coombs' : coombs, 
    'Baldwin' : baldwin, 
    'Weak Nanson' : weak_nanson,
    'Kemeny-Young' : kemeny_young
}


dict_rules_colors = {
    'Plurality':'r',
    'Borda':'b', 
    'Copeland':'y',
    'RandomRule':'c'
}


# Dictionary of sampling methods

# more colloquial names of sampling methods
dict_sampling_methods = {
    'IC' : 'IC',
    'URN-R' : 'Urn', 
    'MALLOWS-RELPHI' : 'Mallows', 
    'euclidean' : 'Euclidean', 
}



# Dictionary of axioms


dict_axioms = {
    'Anonymity':ax.ax_anonymity,
    'Weak anonymity':ax.ax_anonymity_weak,
    'Neutrality':ax.ax_neutrality,
    'Weak neutrality':ax.ax_neutrality_weak,
    'Condorcet':ax.ax_condorcet,
    'Pareto':ax.ax_pareto,
    'Independence':ax.ax_independence
}

dict_axioms_all = {
    'Anonymity':ax.ax_anonymity,
    'Weak anonymity':ax.ax_anonymity_weak,
    'Neutrality':ax.ax_neutrality,
    'Weak neutrality':ax.ax_neutrality_weak,
    'Unanimity':ax.ax_unanimity,
    'Condorcet':ax.ax_condorcet,
    'Pareto':ax.ax_pareto,
    'Independence':ax.ax_independence
}


# sample sizes for axiom checking
dict_axioms_sample = {
    'Anonymity':50,
    'Weak anonymity':50,
    'Neutrality':50,
    'Weak neutrality':50,
    'Unanimity':None,
    'Condorcet':None,
    'Pareto':None,
    'Independence':4
}

# plotting styles
dict_axioms_style = {
    'Anonymity':'-g',
    'Weak anonymity':'-.g',
    'Neutrality':'-r',
    'Weak neutrality':'-.r',
    'Unanimity':'-c',
    'Condorcet':'-m',
    'Pareto':'-y',
    'Independence':'-k'
}

# axioms to check for rules and their plotting styles
dict_axioms_rules = {
    'Condorcet':':m',
    'Independence':':k'
}

# Styles for resoluteness
dict_resoluteness_styles = {
    'Model resoluteness':'--b',
    'Rule resoluteness':'-.b'
}